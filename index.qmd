---
title: "Random Forests"
author: "Danielle Novinski"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: STA 6257 - Advanced Statistical Modeling
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

## Introduction

This is an introduction to random forests, a machine learning method widely used in a variety of applications. Random forest is an ensemble learning method comprised of multiple decision trees. Decision trees are used for predictions and classification in a variety of artificial intelligence and machine learning tasks. Decision trees divide data by fields, creating subsets called nodes. Cut offs are applied based on statistics. Resampling training data and using multiple trees to reduce bias and variance leads to the random forest approach.[1]

Random forest is a classification and regression ensemble method. Ensemble learning methods use several methods to solve a problem. Diversity among methods is indicated by methods making different errors. This leads to improvements in classifications. Random forest extensions include non-parametric test of significance, weighted voting, dynamic integration, weighted random sampling, online random forest, and genetic algorithms. Applications of random forest include ecology, medicine, astronomy, agriculture, traffic, and bioinformatics.[3]


## Methods

The 

## Analysis and Results

### Data and Vizualisation

A study was conducted to determine how...

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```



### Statistical Modeling

### Conlusion

## References
